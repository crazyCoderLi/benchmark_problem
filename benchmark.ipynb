{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crazyCoderLi/benchmark_problem/blob/main/benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI2b6CFdgjeL"
      },
      "source": [
        "# 1. Preparations\n",
        "Most of these preparations are directly from the official turorials with only a few changes, which mainly include:\n",
        "*   import packages\n",
        "*   download the sample video\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMkav2Y9RnqG"
      },
      "source": [
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torch torchvision\n",
        "    import os\n",
        "    import sys\n",
        "    import torch\n",
        "    \n",
        "if torch.__version__=='1.6.0+cu101' and sys.platform.startswith('linux'):\n",
        "    !pip install pytorchvideo\n",
        "else:\n",
        "    need_pytorchvideo=False\n",
        "    try:\n",
        "        # Running notebook locally\n",
        "        import pytorchvideo\n",
        "    except ModuleNotFoundError:\n",
        "        need_pytorchvideo=True\n",
        "    if need_pytorchvideo:\n",
        "        # Install from GitHub\n",
        "        !pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp1eNyy9Rs9Y"
      },
      "source": [
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ") \n",
        "from typing import Dict\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvNyrHbdSNH3",
        "outputId": "de51982b-b60a-457f-c088-28ea3355f0f4"
      },
      "source": [
        "# Download the example video file\n",
        "!wget https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4 "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-12 07:34:58--  https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 549197 (536K) [video/mp4]\n",
            "Saving to: ‘archery.mp4.1’\n",
            "\n",
            "archery.mp4.1       100%[===================>] 536.33K   613KB/s    in 0.9s    \n",
            "\n",
            "2021-10-12 07:35:00 (613 KB/s) - ‘archery.mp4.1’ saved [549197/549197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ21LzwBhBO_"
      },
      "source": [
        "# 2. Video Preprocessing Class\n",
        "Function: transform the video into a list of tensors that the model can handle.\n",
        "\n",
        "By changing the initialized parameters, we can easily transform the video into different tensors for different models.\n",
        "\n",
        "But in fact, I didn't fully understand the meaning of each parameter, so I just encapsulated them into the simple class and assigned the params default value as in the official sample code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNZAGqAXfPOD"
      },
      "source": [
        "class PackPathway(torch.nn.Module):\n",
        "    '''\n",
        "    Directly copied from the official tutorial,\n",
        "    it is a class to transform the video.\n",
        "    '''\n",
        "    def __init__(self, alpha = 4):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, frames: torch.Tensor):\n",
        "        fast_pathway = frames\n",
        "        # Perform temporal sampling from the fast pathway.\n",
        "        slow_pathway = torch.index_select(\n",
        "            frames,\n",
        "            1,\n",
        "            torch.linspace(\n",
        "                0, frames.shape[1] - 1, frames.shape[1] // self.alpha\n",
        "            ).long(),\n",
        "        )\n",
        "        frame_list = [slow_pathway, fast_pathway]\n",
        "        return frame_list\n",
        "\n",
        "\n",
        "class Preprocess():\n",
        "    ####################\n",
        "    # SlowFast transform\n",
        "    ####################\n",
        "    '''\n",
        "    A class for video transform, I have encapsulated the responsibility\n",
        "    of data preprocess into this class.\n",
        "    You can meet the requirements of each model by changing the parameters.\n",
        "    In fact, I didn't fully understand the meaning of each parameter, through I have tried.\n",
        "    so I just give them default value as in the official sample code.\n",
        "    '''\n",
        "    def __init__(\n",
        "            self,\n",
        "            video_path,\n",
        "            device = \"cpu\",\n",
        "            side_size = 256,\n",
        "            mean=[0.45, 0.45, 0.45],\n",
        "            std = [0.225, 0.225, 0.225],\n",
        "            crop_size = 256,\n",
        "            num_frames = 32,\n",
        "            sampling_rate = 2,\n",
        "            frames_per_second = 30,\n",
        "\n",
        "    ):\n",
        "        self.video_path = video_path\n",
        "        self.device = device\n",
        "        self.side_size = side_size\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.crop_size = crop_size\n",
        "        self.num_frames = num_frames\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.frames_per_second = frames_per_second\n",
        "\n",
        "        self.clip_duration = self.get_clip_duration()\n",
        "\n",
        "\n",
        "    def transform(self):\n",
        "        '''\n",
        "        Define a video transformation pipeline, \n",
        "        I have no experience in the Video Process field before,\n",
        "        so I don't fully understand the transformation details.\n",
        "        :return:\n",
        "        '''\n",
        "        trans = ApplyTransformToKey(\n",
        "            key=\"video\",\n",
        "            transform=Compose(\n",
        "                [\n",
        "                    UniformTemporalSubsample(self.num_frames),\n",
        "                    Lambda(lambda x: x / 255.0),\n",
        "                    NormalizeVideo(self.mean, self.std),\n",
        "                    ShortSideScale(\n",
        "                        size=self.side_size\n",
        "                    ),\n",
        "                    CenterCropVideo(self.crop_size),\n",
        "                    PackPathway()\n",
        "                ]\n",
        "            ),\n",
        "        )\n",
        "        return trans\n",
        "\n",
        "    def get_clip_duration(self):\n",
        "        '''\n",
        "        According to the official tutorial, this part may change with\n",
        "        the specific model, so I made it a separate method.\n",
        "        :return: the clip duration.\n",
        "        '''\n",
        "        return (self.num_frames * self.sampling_rate) / self.frames_per_second\n",
        "\n",
        "    def get_processed_data(self):\n",
        "        '''\n",
        "        Process the video into a list of tensors.\n",
        "        :return: the tensors.\n",
        "        '''\n",
        "        start_sec = 0\n",
        "        end_sec = start_sec + self.clip_duration\n",
        "\n",
        "        # Initialize an EncodedVideo helper class\n",
        "        video = EncodedVideo.from_path(self.video_path)\n",
        "\n",
        "        # Load the desired clip\n",
        "        video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "        # Apply a transform to normalize the video input\n",
        "        video_data = self.transform()(video_data)\n",
        "\n",
        "        # Move the inputs to the desired device\n",
        "        inputs = video_data[\"video\"]\n",
        "        inputs = [i.to(self.device)[None, ...] for i in inputs]\n",
        "\n",
        "        return inputs\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjI1qSGyhqbu"
      },
      "source": [
        "# 3. Benchmarking Script Class\n",
        "Function: load a model, run and evaluate its inference performance\n",
        "\n",
        "By running the same sample data repeatly, we can record its single and total running time, which can help us get statistical results of latencies and throughput.\n",
        "\n",
        "We can easily load different pre-trained model form torchhub by assigning different model names when initializing the class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpQtHuU0Nlak"
      },
      "source": [
        "class BenchmarkingScript():\n",
        "    '''\n",
        "    A class for running the model inference with metrics testing. User can\n",
        "    call the the method to run and test the model and print the tested\n",
        "    latency and throughput.\n",
        "    '''\n",
        "    def __init__(\n",
        "            self,\n",
        "            # video_path,\n",
        "            preprocess_class,\n",
        "            running_times,\n",
        "            device,\n",
        "            model_source,\n",
        "            model_name,\n",
        "            pretrained: bool = True\n",
        "    ):\n",
        "        '''\n",
        "        # :param video_path: the path of the video which you want to infer repeatly.\n",
        "        # :param preprocess_class: the class name that you want to preprocess the data.\n",
        "        :param running_times: times you want to run.\n",
        "        :param device: device to run the model.\n",
        "        :param model_source: the models are loaded from torchhub, you should give the source and name of the model.\n",
        "        :param model_name: the name of the model you want to load.\n",
        "        :param pretrained: default is True.\n",
        "        '''\n",
        "        # self.video_path = video_path\n",
        "        self.preprocess_class = preprocess_class\n",
        "        self.running_times = running_times\n",
        "        self.device = device\n",
        "\n",
        "        self.model_source = model_source\n",
        "        self.model_name = model_name\n",
        "        self.pretrained = pretrained\n",
        "\n",
        "        self.throughput = 0\n",
        "        self.latency_list = []\n",
        "\n",
        "        self.processed_data = self.preprocess()\n",
        "        self.model = self.load_model()\n",
        "\n",
        "    def preprocess(self):\n",
        "        '''\n",
        "        For different models, we need different preprocessing classes,\n",
        "        we can just pass different\n",
        "        :param preprocess_class: you can pass different preprocess class for different goals.\n",
        "        :return: the processed data\n",
        "        '''\n",
        "        return self.preprocess_class.get_processed_data()\n",
        "\n",
        "\n",
        "    def load_model(self):\n",
        "        '''\n",
        "        The model will load from the torchhub, you can just pass the source and name of the model,\n",
        "        and it will be loaded automaticly.\n",
        "        :return: the model loaded from torchhub\n",
        "        '''\n",
        "        tempmodel = torch.hub.load(self.model_source, model=self.model_name, pretrained=self.pretrained)\n",
        "        return tempmodel\n",
        "\n",
        "    def run_script(self):\n",
        "        '''\n",
        "        The main function for running the model with metrics testing.\n",
        "        :return: Nothing\n",
        "        '''\n",
        "\n",
        "        # move the model to desired device and turn to eval mode.\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model = self.model.eval()\n",
        "\n",
        "        #warmup, discard the first few running data\n",
        "        print(\"Start warming up!\")\n",
        "        for i in range(10):\n",
        "            temp_data = copy.deepcopy(self.processed_data)\n",
        "            self.model(temp_data)\n",
        "            print(f'\\tWarming up for {i+1} times')\n",
        "        print(\"Warm up is over!\")\n",
        "\n",
        "        # start to infer!\n",
        "        ful_start_time = time.time()\n",
        "        for i in range(self.running_times):\n",
        "            one_start_time = time.time()\n",
        "            temp_data = copy.deepcopy(self.processed_data)\n",
        "            self.model(temp_data)\n",
        "            one_end_time = time.time()\n",
        "            one_time = one_end_time - one_start_time\n",
        "            self.latency_list.append(one_time)\n",
        "            print(f'times:{i} latency:{one_time}')\n",
        "\n",
        "        ful_end_time = time.time()\n",
        "        ful_time = ful_end_time - ful_start_time\n",
        "\n",
        "        self.throughput = self.running_times / ful_time\n",
        "\n",
        "        p50_latency = np.percentile(self.latency_list, 50)\n",
        "        p95_latency = np.percentile(self.latency_list, 95)\n",
        "        p99_latency = np.percentile(self.latency_list, 99)\n",
        "\n",
        "        print(\"==================================\")\n",
        "        print(f'Full running time: {ful_time}')\n",
        "        print(f'throughput: {self.throughput} times/sec')\n",
        "        print(f'p50_latency: {p50_latency}')\n",
        "        print(f'p95_latency: {p95_latency}')\n",
        "        print(f'p99_latency: {p99_latency}')\n",
        "        print(\"==================================\")\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xm1RovWVSc2L",
        "outputId": "d07f4ed6-b527-4c1c-8bf6-50df12e9023b"
      },
      "source": [
        "pre = Preprocess(\"archery.mp4\")\n",
        "\n",
        "sc = BenchmarkingScript(\n",
        "    preprocess_class=pre,\n",
        "    running_times=100,\n",
        "    device=\"cpu\",\n",
        "    model_source=\"facebookresearch/pytorchvideo:main\",\n",
        "    model_name=\"slowfast_r50\"\n",
        ")\n",
        "sc.run_script()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/pytorchvideo/archive/main.zip\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/SLOWFAST_8x8_R50.pyth\" to /root/.cache/torch/hub/checkpoints/SLOWFAST_8x8_R50.pyth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bce2902da5c247548c006aff01899186",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/264M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start warming up!\n",
            "\tWarming up for 1 times\n",
            "\tWarming up for 2 times\n",
            "\tWarming up for 3 times\n",
            "\tWarming up for 4 times\n",
            "\tWarming up for 5 times\n",
            "\tWarming up for 6 times\n",
            "\tWarming up for 7 times\n",
            "\tWarming up for 8 times\n",
            "\tWarming up for 9 times\n",
            "\tWarming up for 10 times\n",
            "Warm up is over!\n",
            "times:0 latency:5.71503472328186\n",
            "times:1 latency:5.731809377670288\n",
            "times:2 latency:5.726421594619751\n",
            "times:3 latency:5.702890396118164\n",
            "times:4 latency:5.767206192016602\n",
            "times:5 latency:5.7390525341033936\n",
            "times:6 latency:5.765338897705078\n",
            "times:7 latency:5.677489757537842\n",
            "times:8 latency:5.661489248275757\n",
            "times:9 latency:5.705151319503784\n",
            "times:10 latency:5.700153112411499\n",
            "times:11 latency:5.640721321105957\n",
            "times:12 latency:5.7169880867004395\n",
            "times:13 latency:5.722662448883057\n",
            "times:14 latency:5.691630125045776\n",
            "times:15 latency:5.6977620124816895\n",
            "times:16 latency:5.656634569168091\n",
            "times:17 latency:5.688710451126099\n",
            "times:18 latency:5.7059266567230225\n",
            "times:19 latency:5.7385094165802\n",
            "times:20 latency:5.739637136459351\n",
            "times:21 latency:5.724775314331055\n",
            "times:22 latency:5.711675405502319\n",
            "times:23 latency:5.698934555053711\n",
            "times:24 latency:5.65730881690979\n",
            "times:25 latency:5.760503530502319\n",
            "times:26 latency:5.746623277664185\n",
            "times:27 latency:5.69135594367981\n",
            "times:28 latency:5.667772054672241\n",
            "times:29 latency:5.639551162719727\n",
            "times:30 latency:5.6761884689331055\n",
            "times:31 latency:5.697164058685303\n",
            "times:32 latency:5.624933242797852\n",
            "times:33 latency:5.731747388839722\n",
            "times:34 latency:5.68658185005188\n",
            "times:35 latency:5.725436449050903\n",
            "times:36 latency:5.731934070587158\n",
            "times:37 latency:5.718188285827637\n",
            "times:38 latency:5.661285161972046\n",
            "times:39 latency:5.84202241897583\n",
            "times:40 latency:6.38296365737915\n",
            "times:41 latency:5.776313781738281\n",
            "times:42 latency:5.743149757385254\n",
            "times:43 latency:5.726000785827637\n",
            "times:44 latency:5.704145431518555\n",
            "times:45 latency:5.763311862945557\n",
            "times:46 latency:5.707740306854248\n",
            "times:47 latency:5.7187042236328125\n",
            "times:48 latency:5.655422210693359\n",
            "times:49 latency:5.663920879364014\n",
            "times:50 latency:5.680112600326538\n",
            "times:51 latency:5.725930690765381\n",
            "times:52 latency:5.700216770172119\n",
            "times:53 latency:5.668991327285767\n",
            "times:54 latency:5.730452537536621\n",
            "times:55 latency:5.7084314823150635\n",
            "times:56 latency:5.749509811401367\n",
            "times:57 latency:5.748988389968872\n",
            "times:58 latency:5.772507905960083\n",
            "times:59 latency:5.786339044570923\n",
            "times:60 latency:5.714874267578125\n",
            "times:61 latency:5.786710500717163\n",
            "times:62 latency:5.801255941390991\n",
            "times:63 latency:5.78344202041626\n",
            "times:64 latency:5.784459352493286\n",
            "times:65 latency:5.738262891769409\n",
            "times:66 latency:5.726629018783569\n",
            "times:67 latency:5.80651068687439\n",
            "times:68 latency:5.749483585357666\n",
            "times:69 latency:5.768081903457642\n",
            "times:70 latency:5.767970323562622\n",
            "times:71 latency:5.759386301040649\n",
            "times:72 latency:5.789545774459839\n",
            "times:73 latency:5.757616758346558\n",
            "times:74 latency:5.761327505111694\n",
            "times:75 latency:5.791438579559326\n",
            "times:76 latency:5.757266521453857\n",
            "times:77 latency:5.741631984710693\n",
            "times:78 latency:5.733750820159912\n",
            "times:79 latency:5.742297887802124\n",
            "times:80 latency:5.7838380336761475\n",
            "times:81 latency:5.726164102554321\n",
            "times:82 latency:5.734930038452148\n",
            "times:83 latency:5.773232936859131\n",
            "times:84 latency:5.7316741943359375\n",
            "times:85 latency:5.70553183555603\n",
            "times:86 latency:5.692530393600464\n",
            "times:87 latency:5.708815574645996\n",
            "times:88 latency:5.752677917480469\n",
            "times:89 latency:5.67483115196228\n",
            "times:90 latency:5.739535093307495\n",
            "times:91 latency:5.714376926422119\n",
            "times:92 latency:5.72624659538269\n",
            "times:93 latency:5.726562738418579\n",
            "times:94 latency:5.689106225967407\n",
            "times:95 latency:5.77695631980896\n",
            "times:96 latency:5.7200915813446045\n",
            "times:97 latency:5.686633825302124\n",
            "times:98 latency:5.773928642272949\n",
            "times:99 latency:5.714917182922363\n",
            "==================================\n",
            "Full running time: 573.3392333984375\n",
            "throughput: 0.1744168097606985 times/sec\n",
            "p50_latency: 5.726205348968506\n",
            "p95_latency: 5.789640414714814\n",
            "p99_latency: 5.847431831359866\n",
            "==================================\n"
          ]
        }
      ]
    }
  ]
}