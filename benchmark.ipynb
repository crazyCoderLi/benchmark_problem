{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crazyCoderLi/benchmark_problem/blob/main/benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI2b6CFdgjeL"
      },
      "source": [
        "# 1. Preparations\n",
        "Most of these preparations are directly from the official turorials with only a few changes, which mainly include:\n",
        "*   import packages\n",
        "*   download the sample video\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMkav2Y9RnqG"
      },
      "source": [
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torch torchvision\n",
        "    import os\n",
        "    import sys\n",
        "    import torch\n",
        "    \n",
        "if torch.__version__=='1.6.0+cu101' and sys.platform.startswith('linux'):\n",
        "    !pip install pytorchvideo\n",
        "else:\n",
        "    need_pytorchvideo=False\n",
        "    try:\n",
        "        # Running notebook locally\n",
        "        import pytorchvideo\n",
        "    except ModuleNotFoundError:\n",
        "        need_pytorchvideo=True\n",
        "    if need_pytorchvideo:\n",
        "        # Install from GitHub\n",
        "        !pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp1eNyy9Rs9Y"
      },
      "source": [
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ") \n",
        "from typing import Dict\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvNyrHbdSNH3",
        "outputId": "f419962d-db8f-480d-edd4-68c6a729cf41"
      },
      "source": [
        "# Download the example video file\n",
        "!wget https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4 "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-12 12:11:04--  https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 549197 (536K) [video/mp4]\n",
            "Saving to: ‘archery.mp4.2’\n",
            "\n",
            "archery.mp4.2       100%[===================>] 536.33K  2.00MB/s    in 0.3s    \n",
            "\n",
            "2021-10-12 12:11:05 (2.00 MB/s) - ‘archery.mp4.2’ saved [549197/549197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ21LzwBhBO_"
      },
      "source": [
        "# 2. Video Preprocessing Class\n",
        "Function: transform the video into a list of tensors that the model can handle.\n",
        "\n",
        "By changing the parameters, we can easily transform the video into different tensors for different models.\n",
        "\n",
        "But in fact, I didn't fully understand the meaning of each parameter, so I just encapsulated them into the simple class and assigned the params default value as in the official sample code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNZAGqAXfPOD"
      },
      "source": [
        "class PackPathway(torch.nn.Module):\n",
        "    '''\n",
        "    Directly copied from the official tutorial,\n",
        "    it is a part of the transformation pipeline.\n",
        "    '''\n",
        "    def __init__(self, alpha = 4):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, frames: torch.Tensor):\n",
        "        fast_pathway = frames\n",
        "        # Perform temporal sampling from the fast pathway.\n",
        "        slow_pathway = torch.index_select(\n",
        "            frames,\n",
        "            1,\n",
        "            torch.linspace(\n",
        "                0, frames.shape[1] - 1, frames.shape[1] // self.alpha\n",
        "            ).long(),\n",
        "        )\n",
        "        frame_list = [slow_pathway, fast_pathway]\n",
        "        return frame_list\n",
        "\n",
        "\n",
        "class Preprocess():\n",
        "    ####################\n",
        "    # SlowFast transform\n",
        "    ####################\n",
        "    '''\n",
        "    A class for video transformation, I have encapsulated the responsibility\n",
        "    of data preprocess into this class.\n",
        "    You can get different data formats which adapt for different models by changing parameters.\n",
        "\n",
        "    In fact, I didn't fully understand the meaning of each parameter in short time, through I have tried.\n",
        "    so I just give them default value as in the official sample code.\n",
        "    '''\n",
        "    def __init__(\n",
        "            self,\n",
        "            video_path,\n",
        "            device = \"cuda\",\n",
        "            side_size = 256,\n",
        "            mean=[0.45, 0.45, 0.45],\n",
        "            std = [0.225, 0.225, 0.225],\n",
        "            crop_size = 256,\n",
        "            num_frames = 32,\n",
        "            sampling_rate = 2,\n",
        "            frames_per_second = 30,\n",
        "\n",
        "    ):\n",
        "        self.video_path = video_path\n",
        "        self.device = device\n",
        "        self.side_size = side_size\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.crop_size = crop_size\n",
        "        self.num_frames = num_frames\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.frames_per_second = frames_per_second\n",
        "\n",
        "        self.clip_duration = self.get_clip_duration()\n",
        "\n",
        "\n",
        "    def transform(self):\n",
        "        '''\n",
        "        Define a video transformation pipeline.\n",
        "\n",
        "        I have no experience in the Video Process field before,\n",
        "        so I don't fully understand the transformation details.\n",
        "        :return:\n",
        "        '''\n",
        "        trans = ApplyTransformToKey(\n",
        "            key=\"video\",\n",
        "            transform=Compose(\n",
        "                [\n",
        "                    UniformTemporalSubsample(self.num_frames),\n",
        "                    Lambda(lambda x: x / 255.0),\n",
        "                    NormalizeVideo(self.mean, self.std),\n",
        "                    ShortSideScale(\n",
        "                        size=self.side_size\n",
        "                    ),\n",
        "                    CenterCropVideo(self.crop_size),\n",
        "                    PackPathway()\n",
        "                ]\n",
        "            ),\n",
        "        )\n",
        "        return trans\n",
        "\n",
        "    def get_clip_duration(self):\n",
        "        '''\n",
        "        According to the official tutorial, this part may change\n",
        "        with the specific model, so I made it a separate method.\n",
        "        If this implementation is not adapted to your model, you can\n",
        "        inherit this class and overwrite this function.\n",
        "        :return: the clip duration.\n",
        "        '''\n",
        "        return (self.num_frames * self.sampling_rate) / self.frames_per_second\n",
        "\n",
        "    def get_processed_data(self):\n",
        "        '''\n",
        "        Process the video into a list of tensors.\n",
        "        :return: the tensors.\n",
        "        '''\n",
        "        start_sec = 0\n",
        "        end_sec = start_sec + self.clip_duration\n",
        "\n",
        "        # Initialize an EncodedVideo helper class\n",
        "        video = EncodedVideo.from_path(self.video_path)\n",
        "\n",
        "        # Load the desired clip\n",
        "        video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "        # Apply a transform to normalize the video input\n",
        "        video_data = self.transform()(video_data)\n",
        "\n",
        "        # Move the inputs to the desired device\n",
        "        inputs = video_data[\"video\"]\n",
        "        inputs = [i.to(self.device)[None, ...] for i in inputs]\n",
        "\n",
        "        return inputs\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjI1qSGyhqbu"
      },
      "source": [
        "# 3. Benchmarking Script Class\n",
        "Function: load a model, run and evaluate its inference performance\n",
        "\n",
        "By running the same sample data repeatly, we can record its single and total running time, which can help us get statistical results of latencies and throughput.\n",
        "\n",
        "We can easily load different pre-trained model from Torch Hub by assigning different model names when initializing the class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpQtHuU0Nlak"
      },
      "source": [
        "class BenchmarkingScript():\n",
        "    '''\n",
        "    A class for running the model inference with metrics testing. User can\n",
        "    use this class to run and test the model and print the tested\n",
        "    latency and throughput.\n",
        "    '''\n",
        "    def __init__(\n",
        "            self,\n",
        "            preprocess_class,\n",
        "            running_times,\n",
        "            device,\n",
        "            model_source,\n",
        "            model_name,\n",
        "            pretrained: bool = True\n",
        "    ):\n",
        "        '''\n",
        "        :param preprocess_class: the class that you want to preprocess the data.\n",
        "        :param running_times: times you want to run.\n",
        "        :param device: device to run the model.\n",
        "        :param model_source: the models are loaded from torchhub, you should give the source and name of the model.\n",
        "        :param model_name: the name of the model you want to load.\n",
        "        :param pretrained: default is True.\n",
        "        '''\n",
        "        self.preprocess_class = preprocess_class\n",
        "        self.running_times = running_times\n",
        "        self.device = device\n",
        "\n",
        "        self.model_source = model_source\n",
        "        self.model_name = model_name\n",
        "        self.pretrained = pretrained\n",
        "\n",
        "        self.throughput = 0\n",
        "        self.latency_list = []\n",
        "\n",
        "        self.processed_data = self.preprocess()\n",
        "        self.model = self.load_model()\n",
        "\n",
        "    def preprocess(self):\n",
        "        '''\n",
        "        Use the preprocess class to provide data for the model,\n",
        "        the video will be processed into a list of tensors through the class.\n",
        "        :return: the processed data\n",
        "        '''\n",
        "        return self.preprocess_class.get_processed_data()\n",
        "\n",
        "\n",
        "    def load_model(self):\n",
        "        '''\n",
        "        The model will load from Torch Hub, you can just pass the source and name of the model,\n",
        "        and it will be loaded automaticly.\n",
        "        :return: the model loaded from torchhub\n",
        "        '''\n",
        "        temp_model = torch.hub.load(self.model_source, model=self.model_name, pretrained=self.pretrained)\n",
        "        return temp_model\n",
        "\n",
        "    def run_script(self):\n",
        "        '''\n",
        "        The main function for running the model with metrics testing.\n",
        "        '''\n",
        "\n",
        "        # move the model to desired device and turn to eval mode.\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model = self.model.eval()\n",
        "\n",
        "        #warmup, discard the first few running data\n",
        "        print(\"Start warming up!\")\n",
        "        for i in range(10):\n",
        "            temp_data = copy.deepcopy(self.processed_data)\n",
        "            self.model(temp_data)\n",
        "            print(f'\\tWarming up for {i+1} times')\n",
        "        print(\"Warm up is over!\")\n",
        "\n",
        "        # start to infer!\n",
        "        ful_start_time = time.time()\n",
        "        for i in range(self.running_times):\n",
        "            one_start_time = time.time()\n",
        "            temp_data = copy.deepcopy(self.processed_data)\n",
        "            self.model(temp_data)\n",
        "            one_end_time = time.time()\n",
        "            one_time = one_end_time - one_start_time\n",
        "            self.latency_list.append(one_time)\n",
        "            print(f'times:{i} latency:{one_time}')\n",
        "\n",
        "        ful_end_time = time.time()\n",
        "        ful_time = ful_end_time - ful_start_time\n",
        "\n",
        "        self.throughput = self.running_times / ful_time\n",
        "\n",
        "        p50_latency = np.percentile(self.latency_list, 50)\n",
        "        p95_latency = np.percentile(self.latency_list, 95)\n",
        "        p99_latency = np.percentile(self.latency_list, 99)\n",
        "\n",
        "        print(\"==================================\")\n",
        "        print(f'Full running time: {ful_time}')\n",
        "        print(f'throughput: {self.throughput} times/sec')\n",
        "        print(f'p50_latency: {p50_latency}')\n",
        "        print(f'p95_latency: {p95_latency}')\n",
        "        print(f'p99_latency: {p99_latency}')\n",
        "        print(\"==================================\")\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm1RovWVSc2L",
        "outputId": "f4f22d0a-6be3-4466-8203-437e35f330e8"
      },
      "source": [
        "pre = Preprocess(\"archery.mp4\", device=\"cuda\")\n",
        "\n",
        "sc = BenchmarkingScript(\n",
        "    preprocess_class=pre,\n",
        "    running_times=100,\n",
        "    device=\"cuda\",\n",
        "    model_source=\"facebookresearch/pytorchvideo:main\",\n",
        "    model_name=\"slowfast_r101\"\n",
        ")\n",
        "sc.run_script()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start warming up!\n",
            "\tWarming up for 1 times\n",
            "\tWarming up for 2 times\n",
            "\tWarming up for 3 times\n",
            "\tWarming up for 4 times\n",
            "\tWarming up for 5 times\n",
            "\tWarming up for 6 times\n",
            "\tWarming up for 7 times\n",
            "\tWarming up for 8 times\n",
            "\tWarming up for 9 times\n",
            "\tWarming up for 10 times\n",
            "Warm up is over!\n",
            "times:0 latency:0.2876431941986084\n",
            "times:1 latency:0.2844088077545166\n",
            "times:2 latency:0.2869076728820801\n",
            "times:3 latency:0.2837843894958496\n",
            "times:4 latency:0.2843613624572754\n",
            "times:5 latency:0.28436994552612305\n",
            "times:6 latency:0.28140687942504883\n",
            "times:7 latency:0.2844233512878418\n",
            "times:8 latency:0.2852625846862793\n",
            "times:9 latency:0.28372669219970703\n",
            "times:10 latency:0.28381848335266113\n",
            "times:11 latency:0.28270673751831055\n",
            "times:12 latency:0.28689026832580566\n",
            "times:13 latency:0.2850348949432373\n",
            "times:14 latency:0.2835276126861572\n",
            "times:15 latency:0.2832603454589844\n",
            "times:16 latency:0.2870168685913086\n",
            "times:17 latency:0.2852613925933838\n",
            "times:18 latency:0.28331971168518066\n",
            "times:19 latency:0.2868776321411133\n",
            "times:20 latency:0.2852199077606201\n",
            "times:21 latency:0.28542065620422363\n",
            "times:22 latency:0.28238582611083984\n",
            "times:23 latency:0.28800392150878906\n",
            "times:24 latency:0.28521275520324707\n",
            "times:25 latency:0.28864479064941406\n",
            "times:26 latency:0.2880539894104004\n",
            "times:27 latency:0.28491711616516113\n",
            "times:28 latency:0.2827610969543457\n",
            "times:29 latency:0.2866027355194092\n",
            "times:30 latency:0.2827911376953125\n",
            "times:31 latency:0.28562021255493164\n",
            "times:32 latency:0.28724217414855957\n",
            "times:33 latency:0.2870514392852783\n",
            "times:34 latency:0.28429293632507324\n",
            "times:35 latency:0.28399157524108887\n",
            "times:36 latency:0.287853479385376\n",
            "times:37 latency:0.2848544120788574\n",
            "times:38 latency:0.28690528869628906\n",
            "times:39 latency:0.287456750869751\n",
            "times:40 latency:0.28710150718688965\n",
            "times:41 latency:0.28537559509277344\n",
            "times:42 latency:0.28526878356933594\n",
            "times:43 latency:0.28697729110717773\n",
            "times:44 latency:0.28551316261291504\n",
            "times:45 latency:0.2879519462585449\n",
            "times:46 latency:0.28595542907714844\n",
            "times:47 latency:0.28472280502319336\n",
            "times:48 latency:0.28894925117492676\n",
            "times:49 latency:0.28668856620788574\n",
            "times:50 latency:0.283872127532959\n",
            "times:51 latency:0.2862522602081299\n",
            "times:52 latency:0.2864830493927002\n",
            "times:53 latency:0.28814077377319336\n",
            "times:54 latency:0.2837696075439453\n",
            "times:55 latency:0.28768134117126465\n",
            "times:56 latency:0.28618454933166504\n",
            "times:57 latency:0.28167223930358887\n",
            "times:58 latency:0.2886624336242676\n",
            "times:59 latency:0.2854316234588623\n",
            "times:60 latency:0.2891225814819336\n",
            "times:61 latency:0.2864689826965332\n",
            "times:62 latency:0.28787755966186523\n",
            "times:63 latency:0.28552794456481934\n",
            "times:64 latency:0.28272485733032227\n",
            "times:65 latency:0.28486204147338867\n",
            "times:66 latency:0.28728294372558594\n",
            "times:67 latency:0.2866370677947998\n",
            "times:68 latency:0.2844839096069336\n",
            "times:69 latency:0.2855722904205322\n",
            "times:70 latency:0.2849905490875244\n",
            "times:71 latency:0.28736090660095215\n",
            "times:72 latency:0.2853586673736572\n",
            "times:73 latency:0.28553104400634766\n",
            "times:74 latency:0.28941965103149414\n",
            "times:75 latency:0.28533387184143066\n",
            "times:76 latency:0.2834458351135254\n",
            "times:77 latency:0.28734254837036133\n",
            "times:78 latency:0.2840614318847656\n",
            "times:79 latency:0.28554272651672363\n",
            "times:80 latency:0.28754568099975586\n",
            "times:81 latency:0.2876615524291992\n",
            "times:82 latency:0.2857344150543213\n",
            "times:83 latency:0.28478550910949707\n",
            "times:84 latency:0.28650808334350586\n",
            "times:85 latency:0.28341197967529297\n",
            "times:86 latency:0.285369873046875\n",
            "times:87 latency:0.2870359420776367\n",
            "times:88 latency:0.2875180244445801\n",
            "times:89 latency:0.28568148612976074\n",
            "times:90 latency:0.28403258323669434\n",
            "times:91 latency:0.2870452404022217\n",
            "times:92 latency:0.2851443290710449\n",
            "times:93 latency:0.28521084785461426\n",
            "times:94 latency:0.28793907165527344\n",
            "times:95 latency:0.28712964057922363\n",
            "times:96 latency:0.28456926345825195\n",
            "times:97 latency:0.28388166427612305\n",
            "times:98 latency:0.28749537467956543\n",
            "times:99 latency:0.28731441497802734\n",
            "==================================\n",
            "Full running time: 28.613455772399902\n",
            "throughput: 3.49485922970753 times/sec\n",
            "p50_latency: 0.2855294942855835\n",
            "p95_latency: 0.2881659746170044\n",
            "p99_latency: 0.2891255521774292\n",
            "==================================\n"
          ]
        }
      ]
    }
  ]
}