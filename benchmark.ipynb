{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crazyCoderLi/benchmark_problem/blob/main/benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI2b6CFdgjeL"
      },
      "source": [
        "# 1. Preparations\n",
        "Most of these preparations are directly from the official turorials with only a few changes, which mainly include:\n",
        "*   import packages\n",
        "*   download the sample video\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMkav2Y9RnqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a43db7-a878-4b55-b161-256b5b57e318"
      },
      "source": [
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torch torchvision\n",
        "    import os\n",
        "    import sys\n",
        "    import torch\n",
        "    \n",
        "if torch.__version__=='1.6.0+cu101' and sys.platform.startswith('linux'):\n",
        "    !pip install pytorchvideo\n",
        "else:\n",
        "    need_pytorchvideo=False\n",
        "    try:\n",
        "        # Running notebook locally\n",
        "        import pytorchvideo\n",
        "    except ModuleNotFoundError:\n",
        "        need_pytorchvideo=True\n",
        "    if need_pytorchvideo:\n",
        "        # Install from GitHub\n",
        "        !pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorchvideo.git\n",
            "  Cloning https://github.com/facebookresearch/pytorchvideo.git to /tmp/pip-req-build-loynhet6\n",
            "  Running command git clone -q https://github.com/facebookresearch/pytorchvideo.git /tmp/pip-req-build-loynhet6\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20210924.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting av\n",
            "  Downloading av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2 MB 32 kB/s \n",
            "\u001b[?25hCollecting parameterized\n",
            "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pytorchvideo==0.1.3) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (1.19.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (4.62.3)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.3-py3-none-any.whl size=184038 sha256=de7f1bed16038c75ac1b71a5a13d087bf9f58419c0f69dd78f82e41cdd65e658\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3i_uqo7r/wheels/87/af/3d/0f80973f39ae2239c1ee9496b333ef4e90bf2d80d486b50eca\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20210924-py3-none-any.whl size=60829 sha256=e33b39c511d13bade56b1266b595b1410def4d216367b961d8cadfe0456ca906\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/c6/de/aa41c65141bdbc9a8aa4b303ce26482aa2f1720ff41b7f17c3\n",
            "Successfully built pytorchvideo fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, iopath, parameterized, fvcore, av, pytorchvideo\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed av-8.0.3 fvcore-0.1.5.post20210924 iopath-0.1.9 parameterized-0.8.1 portalocker-2.3.2 pytorchvideo-0.1.3 pyyaml-5.4.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp1eNyy9Rs9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50834ea-ac1e-444b-f7d4-176a24e9e68a"
      },
      "source": [
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ") \n",
        "from typing import Dict\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The _functional_video module is deprecated. Please use the functional module instead.\n",
            "  \"The _functional_video module is deprecated. Please use the functional module instead.\"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/_transforms_video.py:26: UserWarning: The _transforms_video module is deprecated. Please use the transforms module instead.\n",
            "  \"The _transforms_video module is deprecated. Please use the transforms module instead.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvNyrHbdSNH3",
        "outputId": "94fcd120-dd36-44c6-a819-518fa1a0ed2c"
      },
      "source": [
        "# Download the example video file\n",
        "!wget https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4 "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-12 02:43:20--  https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 549197 (536K) [video/mp4]\n",
            "Saving to: ‘archery.mp4’\n",
            "\n",
            "archery.mp4         100%[===================>] 536.33K  1.57MB/s    in 0.3s    \n",
            "\n",
            "2021-10-12 02:43:20 (1.57 MB/s) - ‘archery.mp4’ saved [549197/549197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ21LzwBhBO_"
      },
      "source": [
        "# 2. Video Preprocessing Class\n",
        "Function: transform the video into a list of tensors that the model can handle.\n",
        "\n",
        "By changing the initialized parameters, we can easily transform the video into different tensors for different models.\n",
        "\n",
        "But in fact, I didn't fully understand the meaning of each parameter, so I just encapsulated them into the simple class and assigned the params default value as in the official sample code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNZAGqAXfPOD"
      },
      "source": [
        "class PackPathway(torch.nn.Module):\n",
        "    def __init__(self, alpha = 4):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, frames: torch.Tensor):\n",
        "        fast_pathway = frames\n",
        "        # Perform temporal sampling from the fast pathway.\n",
        "        slow_pathway = torch.index_select(\n",
        "            frames,\n",
        "            1,\n",
        "            torch.linspace(\n",
        "                0, frames.shape[1] - 1, frames.shape[1] // self.alpha\n",
        "            ).long(),\n",
        "        )\n",
        "        frame_list = [slow_pathway, fast_pathway]\n",
        "        return frame_list\n",
        "\n",
        "\n",
        "class Preprocess():\n",
        "    ####################\n",
        "    # SlowFast transform\n",
        "    ####################\n",
        "    def __init__(\n",
        "            self,\n",
        "            video_path,\n",
        "            device = \"cuda\",\n",
        "            side_size = 256,\n",
        "            mean=[0.45, 0.45, 0.45],\n",
        "            std = [0.225, 0.225, 0.225],\n",
        "            crop_size = 256,\n",
        "            num_frames = 32,\n",
        "            sampling_rate = 2,\n",
        "            frames_per_second = 30,\n",
        "\n",
        "    ):\n",
        "        self.video_path = video_path\n",
        "        self.device = device\n",
        "        self.side_size = side_size\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.crop_size = crop_size\n",
        "        self.num_frames = num_frames\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.frames_per_second = frames_per_second\n",
        "\n",
        "        self.clip_duration = self.get_clip_duration()\n",
        "\n",
        "\n",
        "    def transform(self):\n",
        "        trans = ApplyTransformToKey(\n",
        "            key=\"video\",\n",
        "            transform=Compose(\n",
        "                [\n",
        "                    UniformTemporalSubsample(self.num_frames),\n",
        "                    Lambda(lambda x: x / 255.0),\n",
        "                    NormalizeVideo(self.mean, self.std),\n",
        "                    ShortSideScale(\n",
        "                        size=self.side_size\n",
        "                    ),\n",
        "                    CenterCropVideo(self.crop_size),\n",
        "                    PackPathway()\n",
        "                ]\n",
        "            ),\n",
        "        )\n",
        "        return trans\n",
        "\n",
        "    def get_clip_duration(self):\n",
        "        return (self.num_frames * self.sampling_rate) / self.frames_per_second\n",
        "\n",
        "    def get_processed_data(self):\n",
        "        start_sec = 0\n",
        "        end_sec = start_sec + self.clip_duration\n",
        "\n",
        "        # Initialize an EncodedVideo helper class\n",
        "        video = EncodedVideo.from_path(self.video_path)\n",
        "\n",
        "        # Load the desired clip\n",
        "        video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "        # Apply a transform to normalize the video input\n",
        "        video_data = self.transform()(video_data)\n",
        "\n",
        "        # Move the inputs to the desired device\n",
        "        inputs = video_data[\"video\"]\n",
        "        inputs = [i.to(self.device)[None, ...] for i in inputs]\n",
        "\n",
        "        return inputs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjI1qSGyhqbu"
      },
      "source": [
        "# 3. Benchmarking Script Class\n",
        "Function: load a model, run and evaluate its inference performance\n",
        "\n",
        "By running the same sample data repeatly, we can record its single and total running time, which can help us get statistical results of latencies and throughput.\n",
        "\n",
        "We can easily load different pre-trained model form torchhub by assigning different model names when initializing the class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpQtHuU0Nlak"
      },
      "source": [
        "class BenchmarkingScript():\n",
        "    '''\n",
        "    A class for running the model inference with metrics testing. User can\n",
        "    call the the method to run and test the model and print the tested\n",
        "    latency and throughput.\n",
        "    '''\n",
        "    def __init__(\n",
        "            self,\n",
        "            video_path,\n",
        "            preprocess_class,\n",
        "            running_times,\n",
        "            device,\n",
        "            model_source,\n",
        "            model_name,\n",
        "            pretrained: bool = True\n",
        "    ):\n",
        "        '''\n",
        "        :param video_path: the path of the video which you want to infer repeatly.\n",
        "        :param preprocess_class: the class name that you want to preprocess the data.\n",
        "        :param running_times: times you want to run.\n",
        "        :param device: device to run the model.\n",
        "        :param model_source: the models are loaded from torchhub, you should give the source and name of the model.\n",
        "        :param model_name: the name of the model you want to load.\n",
        "        :param pretrained: default is True.\n",
        "        '''\n",
        "        self.video_path = video_path\n",
        "        self.preprocess_class = preprocess_class\n",
        "        self.running_times = running_times\n",
        "        self.device = device\n",
        "\n",
        "        self.model_source = model_source\n",
        "        self.model_name = model_name\n",
        "        self.pretrained = pretrained\n",
        "\n",
        "        self.throughput = 0\n",
        "        self.latency_list = []\n",
        "\n",
        "        self.processed_data = self.preprocess()\n",
        "        self.model = self.load_model()\n",
        "\n",
        "    def preprocess(self):\n",
        "        '''\n",
        "        For different models, we need different preprocessing classes,\n",
        "        we can just pass the class name of preprocessing class to the init argument \"preprocess_class\".\n",
        "        :param preprocess_class: you can pass different preprocess class for different goals.\n",
        "        :return: the processed data\n",
        "        '''\n",
        "        pre = self.preprocess_class(self.video_path)\n",
        "        return pre.get_processed_data()\n",
        "\n",
        "\n",
        "    def load_model(self):\n",
        "        '''\n",
        "        The model will load from the torchhub, you can just pass the source and name of the model,\n",
        "        and it will be loaded automaticly.\n",
        "        :return: the model loaded from torchhub\n",
        "        '''\n",
        "        tempmodel = torch.hub.load(self.model_source, model=self.model_name, pretrained=self.pretrained)\n",
        "        return tempmodel\n",
        "\n",
        "    def run_script(self):\n",
        "        '''\n",
        "        The main function for running the model with metrics testing.\n",
        "        :return: Nothing\n",
        "        '''\n",
        "\n",
        "        # move the model to desired device and turn to eval mode.\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model = self.model.eval()\n",
        "\n",
        "        #warmup, discard the first few running data\n",
        "        print(\"Start warming up!\")\n",
        "        for i in range(10):\n",
        "            temp_data = copy.deepcopy(self.processed_data)\n",
        "            self.model(temp_data)\n",
        "            print(f'\\tWarming up for {i+1} times')\n",
        "        print(\"Warm up is over!\")\n",
        "\n",
        "        # start to infer!\n",
        "        ful_start_time = time.time()\n",
        "        for i in range(self.running_times):\n",
        "            one_start_time = time.time()\n",
        "            temp_data = copy.deepcopy(self.processed_data)\n",
        "            self.model(temp_data)\n",
        "            one_end_time = time.time()\n",
        "            one_time = one_end_time - one_start_time\n",
        "            self.latency_list.append(one_time)\n",
        "            print(f'times:{i} latency:{one_time}')\n",
        "\n",
        "        ful_end_time = time.time()\n",
        "        ful_time = ful_end_time - ful_start_time\n",
        "\n",
        "        self.throughput = self.running_times / ful_time\n",
        "\n",
        "        p50_latency = np.percentile(self.latency_list, 50)\n",
        "        p95_latency = np.percentile(self.latency_list, 95)\n",
        "        p99_latency = np.percentile(self.latency_list, 99)\n",
        "\n",
        "        print(\"==================================\")\n",
        "        print(f'Full running time: {ful_time}')\n",
        "        print(f'throughput: {self.throughput} times/sec')\n",
        "        print(f'p50_latency: {p50_latency}')\n",
        "        print(f'p95_latency: {p95_latency}')\n",
        "        print(f'p99_latency: {p99_latency}')\n",
        "        print(\"==================================\")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm1RovWVSc2L",
        "outputId": "efea50db-947d-4e44-cbc4-ac245cd00063"
      },
      "source": [
        "sc = BenchmarkingScript(\n",
        "    video_path=\"archery.mp4\",\n",
        "    preprocess_class=Preprocess,\n",
        "    running_times=100,\n",
        "    device=\"cuda\",\n",
        "    model_source=\"facebookresearch/pytorchvideo:main\",\n",
        "    model_name=\"slowfast_r50\"\n",
        ")\n",
        "sc.run_script()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start warming up!\n",
            "\tWarming up for 1 times\n",
            "\tWarming up for 2 times\n",
            "\tWarming up for 3 times\n",
            "\tWarming up for 4 times\n",
            "\tWarming up for 5 times\n",
            "\tWarming up for 6 times\n",
            "\tWarming up for 7 times\n",
            "\tWarming up for 8 times\n",
            "\tWarming up for 9 times\n",
            "\tWarming up for 10 times\n",
            "Warm up is over!\n",
            "times:0 latency:0.19149398803710938\n",
            "times:1 latency:0.19211864471435547\n",
            "times:2 latency:0.19182991981506348\n",
            "times:3 latency:0.1910254955291748\n",
            "times:4 latency:0.19181609153747559\n",
            "times:5 latency:0.19239401817321777\n",
            "times:6 latency:0.1922438144683838\n",
            "times:7 latency:0.19068694114685059\n",
            "times:8 latency:0.19369721412658691\n",
            "times:9 latency:0.191619873046875\n",
            "times:10 latency:0.19248247146606445\n",
            "times:11 latency:0.19165611267089844\n",
            "times:12 latency:0.19018769264221191\n",
            "times:13 latency:0.19186782836914062\n",
            "times:14 latency:0.19196796417236328\n",
            "times:15 latency:0.19234681129455566\n",
            "times:16 latency:0.19071650505065918\n",
            "times:17 latency:0.19209694862365723\n",
            "times:18 latency:0.1909482479095459\n",
            "times:19 latency:0.1911945343017578\n",
            "times:20 latency:0.19113564491271973\n",
            "times:21 latency:0.1914515495300293\n",
            "times:22 latency:0.19207048416137695\n",
            "times:23 latency:0.19131755828857422\n",
            "times:24 latency:0.19179081916809082\n",
            "times:25 latency:0.1906423568725586\n",
            "times:26 latency:0.1915874481201172\n",
            "times:27 latency:0.19396710395812988\n",
            "times:28 latency:0.1929919719696045\n",
            "times:29 latency:0.19306087493896484\n",
            "times:30 latency:0.19243168830871582\n",
            "times:31 latency:0.19163918495178223\n",
            "times:32 latency:0.1923980712890625\n",
            "times:33 latency:0.193037748336792\n",
            "times:34 latency:0.19098472595214844\n",
            "times:35 latency:0.1920938491821289\n",
            "times:36 latency:0.19177031517028809\n",
            "times:37 latency:0.19227194786071777\n",
            "times:38 latency:0.19222092628479004\n",
            "times:39 latency:0.1906135082244873\n",
            "times:40 latency:0.19169163703918457\n",
            "times:41 latency:0.19184374809265137\n",
            "times:42 latency:0.19130802154541016\n",
            "times:43 latency:0.19193267822265625\n",
            "times:44 latency:0.19176626205444336\n",
            "times:45 latency:0.19155001640319824\n",
            "times:46 latency:0.1920931339263916\n",
            "times:47 latency:0.1933121681213379\n",
            "times:48 latency:0.19196009635925293\n",
            "times:49 latency:0.1938328742980957\n",
            "times:50 latency:0.19449734687805176\n",
            "times:51 latency:0.19179630279541016\n",
            "times:52 latency:0.19223904609680176\n",
            "times:53 latency:0.19059348106384277\n",
            "times:54 latency:0.19223666191101074\n",
            "times:55 latency:0.19260168075561523\n",
            "times:56 latency:0.1919240951538086\n",
            "times:57 latency:0.19170713424682617\n",
            "times:58 latency:0.19272494316101074\n",
            "times:59 latency:0.19385147094726562\n",
            "times:60 latency:0.19202017784118652\n",
            "times:61 latency:0.1932203769683838\n",
            "times:62 latency:0.19595718383789062\n",
            "times:63 latency:0.19814062118530273\n",
            "times:64 latency:0.19327902793884277\n",
            "times:65 latency:0.19174718856811523\n",
            "times:66 latency:0.19211459159851074\n",
            "times:67 latency:0.1943039894104004\n",
            "times:68 latency:0.1942598819732666\n",
            "times:69 latency:0.19117522239685059\n",
            "times:70 latency:0.1916658878326416\n",
            "times:71 latency:0.19167470932006836\n",
            "times:72 latency:0.19151830673217773\n",
            "times:73 latency:0.19423270225524902\n",
            "times:74 latency:0.19411826133728027\n",
            "times:75 latency:0.1945512294769287\n",
            "times:76 latency:0.19481968879699707\n",
            "times:77 latency:0.1935892105102539\n",
            "times:78 latency:0.1921098232269287\n",
            "times:79 latency:0.19298672676086426\n",
            "times:80 latency:0.1957225799560547\n",
            "times:81 latency:0.19812893867492676\n",
            "times:82 latency:0.19407224655151367\n",
            "times:83 latency:0.19054722785949707\n",
            "times:84 latency:0.19304800033569336\n",
            "times:85 latency:0.1929478645324707\n",
            "times:86 latency:0.19367337226867676\n",
            "times:87 latency:0.19189667701721191\n",
            "times:88 latency:0.19431161880493164\n",
            "times:89 latency:0.19825172424316406\n",
            "times:90 latency:0.1931149959564209\n",
            "times:91 latency:0.1932051181793213\n",
            "times:92 latency:0.19484591484069824\n",
            "times:93 latency:0.19700002670288086\n",
            "times:94 latency:0.19868803024291992\n",
            "times:95 latency:0.19753623008728027\n",
            "times:96 latency:0.19502925872802734\n",
            "times:97 latency:0.1910099983215332\n",
            "times:98 latency:0.193922758102417\n",
            "times:99 latency:0.19459295272827148\n",
            "==================================\n",
            "Full running time: 19.311559677124023\n",
            "throughput: 5.178245655551966 times/sec\n",
            "p50_latency: 0.19216978549957275\n",
            "p95_latency: 0.19702683687210082\n",
            "p99_latency: 0.19825608730316163\n",
            "==================================\n"
          ]
        }
      ]
    }
  ]
}