{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crazyCoderLi/benchmark_problem/blob/main/benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI2b6CFdgjeL"
      },
      "source": [
        "准备工作：\n",
        "导入各种包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMkav2Y9RnqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea39137f-7eeb-4c5a-f6e6-44d57171a776"
      },
      "source": [
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torch torchvision\n",
        "    import os\n",
        "    import sys\n",
        "    import torch\n",
        "    \n",
        "if torch.__version__=='1.6.0+cu101' and sys.platform.startswith('linux'):\n",
        "    !pip install pytorchvideo\n",
        "else:\n",
        "    need_pytorchvideo=False\n",
        "    try:\n",
        "        # Running notebook locally\n",
        "        import pytorchvideo\n",
        "    except ModuleNotFoundError:\n",
        "        need_pytorchvideo=True\n",
        "    if need_pytorchvideo:\n",
        "        # Install from GitHub\n",
        "        !pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorchvideo.git\n",
            "  Cloning https://github.com/facebookresearch/pytorchvideo.git to /tmp/pip-req-build-sd31wxk0\n",
            "  Running command git clone -q https://github.com/facebookresearch/pytorchvideo.git /tmp/pip-req-build-sd31wxk0\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20210924.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting av\n",
            "  Downloading av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2 MB 32 kB/s \n",
            "\u001b[?25hCollecting parameterized\n",
            "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pytorchvideo==0.1.3) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (1.19.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (4.62.3)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorchvideo==0.1.3) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.3-py3-none-any.whl size=184038 sha256=ca2fe50a9080f9f596a158ce14c32e802f5c023ea94b7d2f5eec53f186d4d08e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rzc3zde4/wheels/87/af/3d/0f80973f39ae2239c1ee9496b333ef4e90bf2d80d486b50eca\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20210924-py3-none-any.whl size=60829 sha256=ec861daa6d0f9f2cc2ac97e63fe3733f2b8ce93a59011529861007d22f6a2eb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/c6/de/aa41c65141bdbc9a8aa4b303ce26482aa2f1720ff41b7f17c3\n",
            "Successfully built pytorchvideo fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, iopath, parameterized, fvcore, av, pytorchvideo\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed av-8.0.3 fvcore-0.1.5.post20210924 iopath-0.1.9 parameterized-0.8.1 portalocker-2.3.2 pytorchvideo-0.1.3 pyyaml-5.4.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp1eNyy9Rs9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b16110-1495-42f9-cab2-d8f3b462c8a0"
      },
      "source": [
        "import json \n",
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ") \n",
        "from typing import Dict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The _functional_video module is deprecated. Please use the functional module instead.\n",
            "  \"The _functional_video module is deprecated. Please use the functional module instead.\"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/_transforms_video.py:26: UserWarning: The _transforms_video module is deprecated. Please use the transforms module instead.\n",
            "  \"The _transforms_video module is deprecated. Please use the transforms module instead.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugHUS89ng52A"
      },
      "source": [
        "下载示例视频"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvNyrHbdSNH3",
        "outputId": "355a61fa-ab9f-4e8f-84a8-ad9cd16737f3"
      },
      "source": [
        "# Download the example video file\n",
        "!wget https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4 "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-11 09:23:14--  https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 549197 (536K) [video/mp4]\n",
            "Saving to: ‘archery.mp4’\n",
            "\n",
            "archery.mp4         100%[===================>] 536.33K  1.86MB/s    in 0.3s    \n",
            "\n",
            "2021-10-11 09:23:15 (1.86 MB/s) - ‘archery.mp4’ saved [549197/549197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ21LzwBhBO_"
      },
      "source": [
        "视频预处理类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNZAGqAXfPOD"
      },
      "source": [
        "class PackPathway(torch.nn.Module):\n",
        "    def __init__(self, alpha = 4):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, frames: torch.Tensor):\n",
        "        fast_pathway = frames\n",
        "        # Perform temporal sampling from the fast pathway.\n",
        "        slow_pathway = torch.index_select(\n",
        "            frames,\n",
        "            1,\n",
        "            torch.linspace(\n",
        "                0, frames.shape[1] - 1, frames.shape[1] // self.alpha\n",
        "            ).long(),\n",
        "        )\n",
        "        frame_list = [slow_pathway, fast_pathway]\n",
        "        return frame_list\n",
        "\n",
        "\n",
        "class Preprocess():\n",
        "    ####################\n",
        "    # SlowFast transform\n",
        "    ####################\n",
        "    def __init__(\n",
        "            self,\n",
        "            video_path,\n",
        "            device = \"cuda\",\n",
        "            side_size = 256,\n",
        "            mean=[0.45, 0.45, 0.45],\n",
        "            std = [0.225, 0.225, 0.225],\n",
        "            crop_size = 256,\n",
        "            num_frames = 32,\n",
        "            sampling_rate = 2,\n",
        "            frames_per_second = 30,\n",
        "\n",
        "    ):\n",
        "        self.video_path = video_path\n",
        "        self.device = device\n",
        "        self.side_size = side_size\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.crop_size = crop_size\n",
        "        self.num_frames = num_frames\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.frames_per_second = frames_per_second\n",
        "\n",
        "        self.clip_duration = self.get_clip_duration()\n",
        "\n",
        "\n",
        "    def transform(self):\n",
        "        trans = ApplyTransformToKey(\n",
        "            key=\"video\",\n",
        "            transform=Compose(\n",
        "                [\n",
        "                    UniformTemporalSubsample(self.num_frames),\n",
        "                    Lambda(lambda x: x / 255.0),\n",
        "                    NormalizeVideo(self.mean, self.std),\n",
        "                    ShortSideScale(\n",
        "                        size=self.side_size\n",
        "                    ),\n",
        "                    CenterCropVideo(self.crop_size),\n",
        "                    PackPathway()\n",
        "                ]\n",
        "            ),\n",
        "        )\n",
        "        return trans\n",
        "\n",
        "    def get_clip_duration(self):\n",
        "        return (self.num_frames * self.sampling_rate) / self.frames_per_second\n",
        "\n",
        "    def get_processed_data(self):\n",
        "        start_sec = 0\n",
        "        end_sec = start_sec + self.clip_duration\n",
        "\n",
        "        # Initialize an EncodedVideo helper class\n",
        "        video = EncodedVideo.from_path(self.video_path)\n",
        "\n",
        "        # Load the desired clip\n",
        "        video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "        # Apply a transform to normalize the video input\n",
        "        video_data = self.transform()(video_data)\n",
        "\n",
        "        # Move the inputs to the desired device\n",
        "        inputs = video_data[\"video\"]\n",
        "        inputs = [i.to(self.device)[None, ...] for i in inputs]\n",
        "\n",
        "        return inputs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjI1qSGyhqbu"
      },
      "source": [
        "benchmark脚本类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpQtHuU0Nlak"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class BenchmarkingScript():\n",
        "    def __init__(\n",
        "            self,\n",
        "            unit_data,\n",
        "            running_times,\n",
        "            device,\n",
        "            model_source,\n",
        "            model_name,\n",
        "            pretrained: bool = True\n",
        "    ):\n",
        "        self.unit_data = unit_data\n",
        "        self.running_times = running_times\n",
        "        self.device = device\n",
        "\n",
        "        self.model_source = model_source\n",
        "        self.model_name = model_name\n",
        "        self.pretrained = pretrained\n",
        "\n",
        "        self.throughput = 0\n",
        "        self.latency_list = []\n",
        "\n",
        "        self.processed_data = self.preprocess(self.unit_data)\n",
        "        self.model = self.load_model()\n",
        "\n",
        "    def preprocess(self, raw_data):\n",
        "        return raw_data\n",
        "\n",
        "\n",
        "    def load_model(self):\n",
        "        tempmodel = torch.hub.load(self.model_source, model=self.model_name, pretrained=self.pretrained)\n",
        "        return tempmodel\n",
        "\n",
        "    def run_script(self):\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model = self.model.eval()\n",
        "\n",
        "        #warmup\n",
        "        print(\"warming up!\")\n",
        "        for i in range(10):\n",
        "            temp_data = copy.deepcopy(self.processed_data)\n",
        "            self.model(temp_data)\n",
        "            print(f'warming up down {i+1} times')\n",
        "        print(\"warming up over!\")\n",
        "\n",
        "        ful_start_time = time.time()\n",
        "        for i in range(self.running_times):\n",
        "            one_start_time = time.time()\n",
        "            temp_data = copy.deepcopy(self.processed_data)\n",
        "            self.model(temp_data)\n",
        "            one_end_time = time.time()\n",
        "            one_time = one_end_time - one_start_time\n",
        "            self.latency_list.append(one_time)\n",
        "            print(f'times:{i} latency:{one_time}')\n",
        "\n",
        "        ful_end_time = time.time()\n",
        "        ful_time = ful_end_time - ful_start_time\n",
        "\n",
        "        self.throughput = self.running_times / ful_time\n",
        "\n",
        "        p50_latency = np.percentile(self.latency_list, 50)\n",
        "        p95_latency = np.percentile(self.latency_list, 95)\n",
        "        p99_latency = np.percentile(self.latency_list, 99)\n",
        "\n",
        "        print(f'full running time: {ful_time: .4f}')\n",
        "        print(f'throughput: {self.throughput: .4f}')\n",
        "        print(f'p50_latency: {p50_latency}')\n",
        "        print(f'p95_latency: {p95_latency}')\n",
        "        print(f'p99_latency: {p99_latency}')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm1RovWVSc2L",
        "outputId": "31a3da59-14de-4374-cab2-de7b8ff4318a"
      },
      "source": [
        "pre = Preprocess(\"archery.mp4\")\n",
        "inputs = pre.get_processed_data()\n",
        "sc = BenchmarkingScript(unit_data=inputs, running_times=100, device=\"cuda\",model_source=\"facebookresearch/pytorchvideo:main\",model_name=\"slowfast_r50\" )\n",
        "sc.run_script()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warming up!\n",
            "warming up down 1 times\n",
            "warming up down 2 times\n",
            "warming up down 3 times\n",
            "warming up down 4 times\n",
            "warming up down 5 times\n",
            "warming up down 6 times\n",
            "warming up down 7 times\n",
            "warming up down 8 times\n",
            "warming up down 9 times\n",
            "warming up down 10 times\n",
            "warming up over!\n",
            "times:0 latency:0.18125486373901367\n",
            "times:1 latency:0.1804673671722412\n",
            "times:2 latency:0.18056440353393555\n",
            "times:3 latency:0.17926931381225586\n",
            "times:4 latency:0.17872214317321777\n",
            "times:5 latency:0.17902660369873047\n",
            "times:6 latency:0.1787407398223877\n",
            "times:7 latency:0.1777198314666748\n",
            "times:8 latency:0.1782841682434082\n",
            "times:9 latency:0.17696189880371094\n",
            "times:10 latency:0.17627429962158203\n",
            "times:11 latency:0.17526555061340332\n",
            "times:12 latency:0.17697620391845703\n",
            "times:13 latency:0.17696833610534668\n",
            "times:14 latency:0.17584538459777832\n",
            "times:15 latency:0.17531752586364746\n",
            "times:16 latency:0.17717957496643066\n",
            "times:17 latency:0.17711544036865234\n",
            "times:18 latency:0.1747446060180664\n",
            "times:19 latency:0.17725706100463867\n",
            "times:20 latency:0.17576336860656738\n",
            "times:21 latency:0.17615962028503418\n",
            "times:22 latency:0.17855215072631836\n",
            "times:23 latency:0.17647838592529297\n",
            "times:24 latency:0.1764981746673584\n",
            "times:25 latency:0.17734026908874512\n",
            "times:26 latency:0.17766833305358887\n",
            "times:27 latency:0.17641305923461914\n",
            "times:28 latency:0.1783757209777832\n",
            "times:29 latency:0.17746257781982422\n",
            "times:30 latency:0.17600059509277344\n",
            "times:31 latency:0.1767568588256836\n",
            "times:32 latency:0.17745423316955566\n",
            "times:33 latency:0.17472434043884277\n",
            "times:34 latency:0.17660784721374512\n",
            "times:35 latency:0.17797636985778809\n",
            "times:36 latency:0.17634892463684082\n",
            "times:37 latency:0.17339181900024414\n",
            "times:38 latency:0.17664337158203125\n",
            "times:39 latency:0.17815327644348145\n",
            "times:40 latency:0.17704057693481445\n",
            "times:41 latency:0.17703938484191895\n",
            "times:42 latency:0.17775368690490723\n",
            "times:43 latency:0.17689299583435059\n",
            "times:44 latency:0.1770641803741455\n",
            "times:45 latency:0.17772412300109863\n",
            "times:46 latency:0.17777252197265625\n",
            "times:47 latency:0.17677974700927734\n",
            "times:48 latency:0.1771559715270996\n",
            "times:49 latency:0.17876887321472168\n",
            "times:50 latency:0.17730140686035156\n",
            "times:51 latency:0.17772817611694336\n",
            "times:52 latency:0.17832517623901367\n",
            "times:53 latency:0.17734694480895996\n",
            "times:54 latency:0.17552638053894043\n",
            "times:55 latency:0.1767740249633789\n",
            "times:56 latency:0.17805027961730957\n",
            "times:57 latency:0.1767570972442627\n",
            "times:58 latency:0.17473530769348145\n",
            "times:59 latency:0.17746782302856445\n",
            "times:60 latency:0.1794602870941162\n",
            "times:61 latency:0.17906665802001953\n",
            "times:62 latency:0.17785859107971191\n",
            "times:63 latency:0.177626371383667\n",
            "times:64 latency:0.17764639854431152\n",
            "times:65 latency:0.17790484428405762\n",
            "times:66 latency:0.17787384986877441\n",
            "times:67 latency:0.17815303802490234\n",
            "times:68 latency:0.17738008499145508\n",
            "times:69 latency:0.17774367332458496\n",
            "times:70 latency:0.17826032638549805\n",
            "times:71 latency:0.17810630798339844\n",
            "times:72 latency:0.1780862808227539\n",
            "times:73 latency:0.177978515625\n",
            "times:74 latency:0.17768454551696777\n",
            "times:75 latency:0.1781461238861084\n",
            "times:76 latency:0.1779487133026123\n",
            "times:77 latency:0.1771259307861328\n",
            "times:78 latency:0.17795753479003906\n",
            "times:79 latency:0.17795729637145996\n",
            "times:80 latency:0.17937350273132324\n",
            "times:81 latency:0.17721199989318848\n",
            "times:82 latency:0.1797325611114502\n",
            "times:83 latency:0.17805862426757812\n",
            "times:84 latency:0.178480863571167\n",
            "times:85 latency:0.17689800262451172\n",
            "times:86 latency:0.18011689186096191\n",
            "times:87 latency:0.17782068252563477\n",
            "times:88 latency:0.17848777770996094\n",
            "times:89 latency:0.1772453784942627\n",
            "times:90 latency:0.1777336597442627\n",
            "times:91 latency:0.1792604923248291\n",
            "times:92 latency:0.17906856536865234\n",
            "times:93 latency:0.17870354652404785\n",
            "times:94 latency:0.17902350425720215\n",
            "times:95 latency:0.17890238761901855\n",
            "times:96 latency:0.17858290672302246\n",
            "times:97 latency:0.17814207077026367\n",
            "times:98 latency:0.17831730842590332\n",
            "times:99 latency:0.17850136756896973\n",
            "full running time:  17.7978\n",
            "throughput:  5.6187\n",
            "p50_latency: 0.177726149559021\n",
            "p95_latency: 0.1794739007949829\n",
            "p99_latency: 0.18057130813598632\n"
          ]
        }
      ]
    }
  ]
}